{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract bubble from simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convenience routine for fitting analysis\n",
    "def log_p(tc,ax):\n",
    "    ax.plot(np.sort(tc[0]),np.log(survive_prob(tc[0],tc[1])))\n",
    "    return\n",
    "\n",
    "# Combined returns to combine various steps in the pipeline\n",
    "def create_times(files,sig_cut=-5):\n",
    "    d = [read_mean_field(f) for f in files]\n",
    "    mu = []; sig = []\n",
    "    for dc in d:\n",
    "        mu.append(np.mean(dc[:,0,1]))\n",
    "        sig.append(np.std(dc[:,0,1]))\n",
    "        myThresh = mu[i]+sig_cut*sig[i]\n",
    "    return [extract_decay_times(tc[:,:,1],thresh=myThresh,cut=myThresh,interp=True,dt=tc[0,0,0]) for i,tc in enumerate(d) ]\n",
    "\n",
    "def get_means_and_sigma(d):\n",
    "    mu = []; sig = []\n",
    "    for dc in d:\n",
    "        mu.append(np.mean(dc[:,0,1]))\n",
    "        sig.append(np.std(dc[:,0,1]))\n",
    "    return np.array(mu), np.array(sig)\n",
    "\n",
    "def decays_from_dat(dat,sigCut=-10,full=False):\n",
    "    mu, sig = get_means_and_sigma(dat)\n",
    "    th = mu + sigCut*sig\n",
    "    if full:\n",
    "        return [extract_decay_times_full(dc[:,:,1],dt=dc[0,0,0],interp=True,thresh=th,cut=th) for dc in d]\n",
    "    return [extract_decay_times(dc[:,:,1],dt=dc[0,0,0],interp=True,thresh=th,cut=th) for dc in d]\n",
    "        \n",
    "# Move this into plotting file\n",
    "def plot_survival(times,a=None):\n",
    "    if a == None:\n",
    "        f,a = plt.subplots()\n",
    "    a.plot(np.sort(times[0]),survive_prob(times[0],times[1]))\n",
    "    return a.get_figure(),a\n",
    "\n",
    "def lin_fit_times(times,tmin,tmax,o=1):\n",
    "    \"\"\"\n",
    "    Given a collection of decay times, do a linear fit to\n",
    "    the logarithmic survival probability between given times\n",
    "    \n",
    "    Input\n",
    "      times : Times object (first index is array of decay times, 2nd is original number of samples\n",
    "      tmin  : minimum time to fit inside\n",
    "      tmax  : maximum time to fit inside\n",
    "    \"\"\"\n",
    "    t = np.sort(times[0])\n",
    "    p = np.log( survive_prob(times[0],times[1]) )\n",
    "    ii = np.where( (t>tmin) & (t<tmax) )\n",
    "    return np.polyfit(t[ii],p[ii],o)\n",
    "\n",
    "def lin_fit_probs(times,pmin,pmax):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    t = np.sort(times[0])\n",
    "    p = np.survive_prob(times[0],times[1])\n",
    "    ii = np.where( (p<pmax) & (p>pmin) )\n",
    "    return np.polyfit( t[ii],np.log(p[ii]) )\n",
    "\n",
    "# File reading and manipulation\n",
    "def read_mean_field(fName):\n",
    "    \"\"\"\n",
    "    Read in time-stream data of mean field from ASCII file.\n",
    "\n",
    "    Assumed format of the file is a file with 4 columns:\n",
    "    Time   <phi>  rho_spec  rho_fd\n",
    "\n",
    "    With trajectories separated by a carriage return.\n",
    "    \n",
    "    This function assumes each sample has the same number of time-steps, which is inferred from the time outputs in the file.  If there is a partial trajectory at the end, it is removed.\n",
    "    \"\"\"\n",
    "    tind = 0\n",
    "    d = np.loadtxt(fName)\n",
    "    dt = np.diff(d[:,tind])\n",
    "    nTstep = np.where(dt<0)[0][0]+1\n",
    "    return d[:d.shape[0]//nTstep*nTstep,:].reshape((-1,nTstep,d.shape[1]))\n",
    "\n",
    "# start debugging this thing\n",
    "# Issues:\n",
    "#   Assumes each files has trajectories with the same number of time-steps\n",
    "def get_trajectories(files,num_tsteps,ax=1):\n",
    "    \"\"\"\n",
    "    Extract the trajectores from a collection of files.\n",
    "\n",
    "    Input:\n",
    "     files      - A list of files to read the trajectories from\n",
    "     num_tsteps - Number of time steps in each trajectory\n",
    "     ax         - Axis storing the trajectories\n",
    "    Output:\n",
    "     d     - A list of numpy arrays containing the decay trajectories of length (num files).  Each numpy array has shape (num_traj,num_tstep)\n",
    "    \"\"\"\n",
    "    d = []\n",
    "    for f in files:\n",
    "        a = np.loadtxt(f)\n",
    "        d.append( a[:a.shape[0]//num_tsteps*num_tsteps,ax].reshape((-1,num_tsteps)) )\n",
    "    return d\n",
    "\n",
    "# Need to debug the interpolation subroutine\n",
    "def extract_decay_times(time_streams,thresh=0.5,cut=0.5,interp=True,up_cross=False,dt=1.,**kwargs):\n",
    "    \"\"\"\n",
    "    Extract the first crossing of a time-stream past some threshold.\n",
    "\n",
    "    time_streams - The time streams to get the upcrossings from.  \n",
    "      Has shape (num_samples,num_tsteps)\n",
    "\n",
    "    thresh - Crossing threshold\n",
    "\n",
    "    cut - During the time-stream, only time-streams that exceed cut are considered to have decayed.\n",
    "\n",
    "    up_cross   - If True look for first upcrossing\n",
    "               - If False look for first downcrossing\n",
    "\n",
    "    interp - If True will linearly interpolate to get the time\n",
    "           - If False will just get the lower bin on the time\n",
    "\n",
    "    dt     - Time step between outputs\n",
    "\n",
    "    Returns:\n",
    "        times    - numpy array of decay times (unsorted)\n",
    "        num_traj - total number of trajectories \n",
    "\n",
    "        Note: Because not all trajectories need decay, times.size may be less than the number of trajectories\n",
    "    \"\"\"\n",
    "    if up_cross:\n",
    "        td = np.where(np.max(time_streams[:,:],axis=-1) > cut)\n",
    "        ti = np.argmax(time_streams[td,:] > thresh,axis=-1)[0]  # Assumes increading\n",
    "    else:\n",
    "        td = np.where(np.min(time_streams[:,:],axis=-1) < cut)\n",
    "        ti = np.argmax(time_streams[td,:] < thresh,axis=-1)[0]\n",
    "\n",
    "    # This needs to be fixed to work when ti = 0, or fucky slope\n",
    "    if interp:\n",
    "        t = ti + (thresh-time_streams[td,ti]) / (time_streams[td,ti]-time_streams[td,ti-1])\n",
    "        t = t[0]\n",
    "    else:\n",
    "        t = ti\n",
    "    return dt*t, time_streams.shape[0]\n",
    "\n",
    "def extract_decay_times_full(time_streams,thresh=0.5,cut=0.5,interp=True,up_cross=False,dt=1.,**kwargs):\n",
    "    \"\"\"\n",
    "    Extract the decay times, including -1 for undecayed trajectories.\n",
    "    This allows a direct comparison between different resolutions using\n",
    "    identical initial conditions.\n",
    "    \"\"\"\n",
    "    t = -np.ones(time_streams.shape[0])/dt  # For future normalisation\n",
    "    if up_cross:\n",
    "        td = np.where(np.max(time_streams[:,:],axis=-1) > cut)\n",
    "        ti = np.argmax(time_streams[td,:] > thresh,axis=-1)[0]\n",
    "    else:\n",
    "        td = np.where(np.min(time_streams[:,:],axis=-1) < cut)\n",
    "        ti = np.argmax(time_streams[td,:] < thresh,axis=-1)[0]\n",
    "\n",
    "    #### Need to add interpolation\n",
    "    if interp:\n",
    "        print(\"Interpolation not yet fully tested\")\n",
    "        t[td] = ti + (thresh-time_streams[td,ti]) / (time_streams[td,ti]-time_streams[td,ti-1])\n",
    "    else:\n",
    "        t[td] = ti\n",
    "    return dt*t\n",
    "\n",
    "def decay_indices(t1,t2):\n",
    "    \"\"\"\n",
    "    Given two streams of input decay times, return the indices where both decay, the first decays but the second doesn't, the second decays but the first doesn't, and where neither decays\n",
    "\n",
    "    Input:\n",
    "     t1 - First set of decay times\n",
    "     t2 - Second set of decay times\n",
    "\n",
    "    Output:\n",
    "     i_dd - Indices where both decay\n",
    "     i_du - Indices where first decays but second doesn't\n",
    "     i_ud - Indices where second decays but first doesn't\n",
    "     i_dd - Indices where neither decays\n",
    "    \"\"\"\n",
    "    i_dd = np.where( (t1>=0.) & (t2>=0.) )\n",
    "    i_du = np.where( (t1>=0.) & (t2<0.) )\n",
    "    i_ud = np.where( (t1<0.) & (t2>=0.) )\n",
    "    i_uu = np.where( (t1<0.) & (t2<0.) )        \n",
    "    return i_dd, i_du, i_ud, i_uu\n",
    "\n",
    "def ind_count(t0,t1,ind,thresh):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "      ind    - The indices where both ensembles decay, one does and the other doesn't, and neither do.  In the form of the output of decay_indices\n",
    "      thresh - Threshold dt for which two decaying trajectories are determined to not match\n",
    "\n",
    "    Returns:\n",
    "      n - Counts of the 4 indices\n",
    "      n_error - Number of misatched trajectories that decayed in both sims\n",
    "    \"\"\"\n",
    "    n = np.array([ic[0].size for ic in ind])\n",
    "    n_error = np.where(np.abs(t0[ind[0]]-t1[ind[0]]) > thresh)[0].size\n",
    "    return n, n_error\n",
    "\n",
    "def error_prob(t_bad,t_res,thresh=0.5):\n",
    "    \"\"\"\n",
    "    Return the fraction of 'bad' decay times given an unresolved and compared resolved simulation\n",
    "\n",
    "    Input:\n",
    "      t_bad : Decay times (including undecayed) times for unresolved sims\n",
    "      t_res : Decay times for resolved simulations\n",
    "      thresh : Error in dt to be considered a bad decay time\n",
    "\n",
    "    Output:\n",
    "      Fraction of bad decay times defined as:\n",
    "        (number_wrong_decays + number_decays_in_unresolved + number_decays_in_resolved) / (number_decays + number_decays_in_unresolved + number_decays_in_resolved)\n",
    "    \"\"\"\n",
    "    ind = decay_indices(t_bad,t_res)\n",
    "    n,n_error = ind_count(t_bad,t_res,ind,thresh)\n",
    "    return (n_error+n[1]+n[2])*1./(n[0]+n[1]+n[2])\n",
    "\n",
    "def bin_decay_times():\n",
    "    \"\"\"\n",
    "    When this is written, I will slice and dice the decay times for identical\n",
    "    choices of simulations\n",
    "    \"\"\"\n",
    "    return\n",
    "\n",
    "# To do: Debug more to ensure all offsets are correct.\n",
    "# I've done a first go through and I think they're ok\n",
    "def survive_prob(t_decay,num_samp):\n",
    "    \"\"\"\n",
    "    Return the survival probability as a function of time.\n",
    "\n",
    "    Input:\n",
    "      t_decay  : Decay times of trajectories\n",
    "      num_samp : Total number of samples in Monte Carlo\n",
    "\n",
    "    Note: Since some trajectories may not decay, t_decay.size isn't always num_sampe\n",
    "\n",
    "    Output:\n",
    "      prob     : Survival Probability\n",
    "\n",
    "    These can be plotted as plt.plot(t_sort,prob) to get a survival probability graph.\n",
    "    \"\"\"\n",
    "    frac_remain = float(num_samp-t_decay.size)/float(num_samp)\n",
    "    prob = 1.-np.linspace(1./num_samp,1.-frac_remain,t_decay.size,endpoint=True)\n",
    "    return prob\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    # Temporary to reduce typing\n",
    "#    fName = 'files-vary-cut.txt'\n",
    "#    fName = 'files-hertzberg-varyL.txt'\n",
    "#    fName = 'files-cut-pairs.txt'\n",
    "#    fName = 'files-cut-base-to-converged.txt'\n",
    "    fName = 'files-check-converged-pairs.txt'\n",
    "    \n",
    "    with open(fName) as f:\n",
    "        files = f.read().splitlines()\n",
    "        \n",
    "    d = [read_mean_field(f) for f in files]\n",
    "    mu,sig = get_means_and_sigma(d)\n",
    "    nsig = -10; th = mu+nsig*sig\n",
    "\n",
    "    tf = [ extract_decay_times_full(dc[:,:,1],dt=dc[0,0,0],thresh=th[i],cut=th[i]) for i,dc in enumerate(d) ]\n",
    "    t = [ extract_decay_times(dc[:,:,1],dt=dc[0,0,0],thresh=th[i],cut=th[i]) for i,dc in enumerate(d) ]\n",
    "    for i in range(3):\n",
    "        print( error_prob(tf[2*i],tf[2*i+1]) )\n",
    "    \n",
    "    fName = 'files-cut-base-to-converged.txt'\n",
    "    with open(fName) as f:\n",
    "        files = f.read().splitlines()\n",
    "        \n",
    "    d = [read_mean_field(f) for f in files]\n",
    "    mu,sig = get_means_and_sigma(d)\n",
    "    for i in range(4):\n",
    "        mu[2*i] = mu[2*i+1]\n",
    "        sig[2*i] = sig[2*i+1]\n",
    "    nsig = -10; th = mu+nsig*sig\n",
    "        \n",
    "    tf = [ extract_decay_times_full(dc[:,:,1],dt=dc[0,1,0]-dc[0,0,0],thresh=th[i],cut=th[i]) for i,dc in enumerate(d) ]\n",
    "    t = [ extract_decay_times(dc[:,:,1],dt=dc[0,1,0]-dc[0,0,0],thresh=th[i],cut=th[i]) for i,dc in enumerate(d) ]\n",
    "    for i in range(4):\n",
    "        print( error_prob(tf[2*i],tf[2*i+1]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nLat = 512\n",
    "nSims = 2\n",
    "tMax = 20000\n",
    "\n",
    "nu = 2.*10**(-3); print('V_0 = ', 4*nu)\n",
    "lamb = 6; print('lamb = ', lamb)\n",
    "m2eff = 4. * nu * (- 1. + lamb**2); print('m2eff = ', m2eff)\n",
    "lenLat = 20. / np.sqrt(2. * nu); print('lenLat = ', lenLat)\n",
    "#paramL = np.arange(2, 4, 1)\n",
    "#paramP = np.arange(8, 15, 2)\n",
    "\n",
    "#lenLat0 = len0*paramL[0]; print(lenLat0)\n",
    "#dx = lenLat0/nLat; print(dx)\n",
    "#dk = 2.*np.pi/lenLat0; print(dk)\n",
    "\n",
    "#lamb = 6; print('lamb = ', lamb)\n",
    "#m2eff = - 1. + lamb**2; print('m2eff = ', m2eff)\n",
    "#lenLat = 512.; print('lenLat = ', lenLat)\n",
    "paramP = np.arange(2, 31, 2)\n",
    "phiMax = -1.54301\n",
    "AA = 10\n",
    "ppp = 3\n",
    "\n",
    "dx = lenLat/nLat; print(dx)\n",
    "dk = 2.*np.pi/lenLat; print(dk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = '_for_lamb{:.4f}'.format(lamb)+'_x'+str(nLat)\n",
    "plots_file = '/home/dpirvu/big_plot_file/thin_wall_average_bubble/'\n",
    "pickle_file = '/gpfs/dpirvu/nonOscillons/'\n",
    "sims_file = '/gpfs/dpirvu/sims/'\n",
    "\n",
    "def sim_location(sim, pot_type, length, phi0):\n",
    "    return sims_file+'typeP'+str(pot_type)+'_len{:.4f}'.format(length)+'_phi0{:.4f}'.format(phi0)+'_lamb{:.4f}'.format(lamb)+'_x'+str(nLat)+'_sim'+str(sim)+'_fields.dat'\n",
    "\n",
    "def extract_data(filename, col):\n",
    "#    print(filename)\n",
    "    file = open(filename,'r')\n",
    "    lines = file.readlines()\n",
    "    lines = [line.replace('\\x00','') for line in lines[3:]]\n",
    "    field_values = [float(line.split()[col]) for line in lines[:]]\n",
    "    file.close()\n",
    "    return field_values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (conda) - recommended",
   "language": "python",
   "name": "python37-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
